{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#my-test3-COOL\" data-toc-modified-id=\"my-test3-COOL-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>my test3 COOL</a></span></li></ul></li><li><span><a href=\"#svrg-new-version-for-time-test\" data-toc-modified-id=\"svrg-new-version-for-time-test-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>svrg new version for time test</a></span><ul class=\"toc-item\"><li><span><a href=\"#TINY-ImageNet\" data-toc-modified-id=\"TINY-ImageNet-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>TINY ImageNet</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T15:37:06.221712Z",
     "start_time": "2018-10-19T15:37:06.135942Z"
    }
   },
   "source": [
    "usenormA and y=0 :49 51 52 50% right\n",
    "usenormA and y=1 : 3\n",
    "usenomaA=1 and use_normy=0 :4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### my test3 COOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T16:54:08.418651Z",
     "start_time": "2018-10-21T16:31:04.481445Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randwho and index_min 21 21\n",
      "randwho and index_min 48 48\n",
      "randwho and index_min 52 52\n",
      "randwho and index_min 35 35\n",
      "randwho and index_min 28 28\n",
      "randwho and index_min 64 64\n",
      "randwho and index_min 46 46\n",
      "randwho and index_min 37 37\n",
      "randwho and index_min 25 25\n",
      "randwho and index_min 63 63\n",
      "randwho and index_min 1 1\n",
      "randwho and index_min 26 26\n",
      "randwho and index_min 46 46\n",
      "randwho and index_min 25 25\n",
      "randwho and index_min 9 9\n",
      "randwho and index_min 19 19\n",
      "randwho and index_min 8 50\n",
      "randwho and index_min 51 51\n",
      "randwho and index_min 46 46\n",
      "randwho and index_min 35 35\n",
      "randwho and index_min 27 45\n",
      "randwho and index_min 19 19\n",
      "randwho and index_min 15 15\n",
      "randwho and index_min 34 34\n",
      "randwho and index_min 32 32\n",
      "randwho and index_min 22 22\n",
      "randwho and index_min 55 55\n",
      "randwho and index_min 25 64\n",
      "randwho and index_min 55 16\n",
      "randwho and index_min 19 11\n",
      "randwho and index_min 8 51\n",
      "randwho and index_min 19 19\n",
      "randwho and index_min 29 29\n",
      "randwho and index_min 2 2\n",
      "randwho and index_min 43 43\n",
      "randwho and index_min 16 16\n",
      "randwho and index_min 12 19\n",
      "randwho and index_min 6 6\n",
      "randwho and index_min 1 1\n",
      "randwho and index_min 57 57\n",
      "randwho and index_min 6 24\n",
      "randwho and index_min 54 54\n",
      "randwho and index_min 6 45\n",
      "randwho and index_min 32 62\n",
      "randwho and index_min 50 50\n",
      "randwho and index_min 23 23\n",
      "randwho and index_min 12 12\n",
      "randwho and index_min 20 20\n",
      "randwho and index_min 24 24\n",
      "randwho and index_min 34 34\n",
      "randwho and index_min 5 5\n",
      "randwho and index_min 4 4\n",
      "randwho and index_min 17 17\n",
      "randwho and index_min 36 36\n",
      "randwho and index_min 33 33\n",
      "randwho and index_min 21 49\n",
      "randwho and index_min 50 50\n",
      "randwho and index_min 54 54\n",
      "randwho and index_min 28 28\n",
      "randwho and index_min 19 19\n",
      "randwho and index_min 52 24\n",
      "randwho and index_min 26 26\n",
      "randwho and index_min 19 19\n",
      "randwho and index_min 17 50\n",
      "randwho and index_min 51 51\n",
      "randwho and index_min 47 47\n",
      "randwho and index_min 56 56\n",
      "randwho and index_min 24 24\n",
      "randwho and index_min 0 0\n",
      "randwho and index_min 0 0\n",
      "randwho and index_min 1 56\n",
      "randwho and index_min 62 62\n",
      "randwho and index_min 17 17\n",
      "randwho and index_min 32 19\n",
      "randwho and index_min 22 22\n",
      "randwho and index_min 63 45\n",
      "randwho and index_min 64 64\n",
      "randwho and index_min 16 16\n",
      "randwho and index_min 19 19\n",
      "randwho and index_min 4 4\n",
      "randwho and index_min 54 54\n",
      "randwho and index_min 7 7\n",
      "randwho and index_min 47 47\n",
      "randwho and index_min 52 52\n",
      "randwho and index_min 6 6\n",
      "randwho and index_min 50 50\n",
      "randwho and index_min 21 21\n",
      "randwho and index_min 5 5\n",
      "randwho and index_min 5 19\n",
      "randwho and index_min 55 50\n",
      "randwho and index_min 63 63\n",
      "randwho and index_min 0 53\n",
      "randwho and index_min 48 48\n",
      "randwho and index_min 28 45\n",
      "randwho and index_min 32 64\n",
      "randwho and index_min 11 11\n",
      "randwho and index_min 15 15\n",
      "randwho and index_min 30 30\n",
      "randwho and index_min 22 22\n",
      "randwho and index_min 8 19\n"
     ]
    }
   ],
   "source": [
    "### import things\n",
    "import pandas as pd\n",
    "import copy\n",
    "### read form the csv doc\n",
    "data_train = pd.read_csv('train.csv')  \n",
    "data_test = pd.read_csv('test.csv')\n",
    "### trans to array\n",
    "train_array = np.array(data_train)\n",
    "test_array = np.array(data_test)\n",
    "###############hyper parameter\n",
    "use_normA=0\n",
    "use_normy=0\n",
    "###############hyper parameter\n",
    "\n",
    "### process the A to be norm or not\n",
    "if use_normA==1: \n",
    "    A_before_norm = train_array\n",
    "    A=np.empty(np.shape(A_before_norm))\n",
    "    for i in range(np.shape(A_before_norm)[1]):\n",
    "        temp=A_before_norm[:,i]/np.linalg.norm(A_before_norm[:,i])\n",
    "        A[:,i]=temp\n",
    "else:\n",
    "    A = train_array\n",
    "\n",
    "### the A shape\n",
    "[d,n] = A.shape\n",
    "\n",
    "\n",
    "### aha! same as the lambda, the L-1 norm coefficent\n",
    "lamb=1e-4\n",
    "\n",
    "### the learning rate 0.15/(the proxi-L constant)\n",
    "alpha=0.15/(0.25*max(sum(A*A)))\n",
    "\n",
    "### loops\n",
    "iters_outer=2\n",
    "iters_inner=2*d\n",
    "\n",
    "### count the number bingo\n",
    "right=0\n",
    "\n",
    "xx_0=np.zeros([85*67,67])\n",
    "for i in range(67):\n",
    "    xx_0[i*85:i*85+85][:,i]=1\n",
    "\n",
    "for k in range(100):\n",
    "    rand_index=np.random.randint(85*67)\n",
    "#     print('rand_index',rand_index)\n",
    "    rand_who=int(rand_index/85)\n",
    "#     print('rand_who',rand_who)\n",
    "    \n",
    "    #### which y version you use, norm processed or the plain one \n",
    "    if use_normy==1:\n",
    "        temp_y = test_array[:,rand_index].reshape(d,1)\n",
    "        y=np.empty(np.shape(temp_y))\n",
    "        y=temp_y/np.linalg.norm(temp_y)\n",
    "    else:\n",
    "        y=test_array[:,rand_index].reshape(d,1)\n",
    "    \n",
    "    ### initialize the two ws\n",
    "    w_prev=np.array(np.zeros([n,1]))\n",
    "    w_tilda=np.array(np.zeros([n,1]))\n",
    "    ### big loop\n",
    "    for i in range(iters_outer):\n",
    "        mu=(-A.T).dot(y-A.dot(w_tilda))/d\n",
    "        ##small loop\n",
    "        for j in range(iters_inner):\n",
    "            ### choose a rand one from d \n",
    "            idx=np.random.randint(0,d)\n",
    "            ### A transpose, need reshape\n",
    "            A_idx=A[idx].T.reshape(n,1)\n",
    "            ### g_prev and tilda\n",
    "            g_prev=(-A_idx).dot(y[idx]-(A[idx].reshape(1,n)).dot(w_prev)) \n",
    "            g_tilda=(-A_idx).dot(y[idx]-(A[idx].reshape(1,n)).dot(w_tilda)) \n",
    "            ### update the parameter\n",
    "            w_prev=w_prev-alpha*(g_prev-g_tilda+mu)\n",
    "            ### the soft thresholding\n",
    "            temp=w_prev-lamb*alpha\n",
    "            temp=(temp+abs(temp))/2\n",
    "            w_prev=np.sign(w_prev)*temp\n",
    "        ### assign the w_tilda for another loop    \n",
    "        w_tilda=copy.deepcopy(w_prev)\n",
    "\n",
    "\n",
    "        \n",
    "    res_min=1e9\n",
    "    for i in range(np.shape(xx_0)[1]):\n",
    "        temp=xx_0[:,i].reshape(5695,1)\n",
    "        x_phi=w_tilda*temp\n",
    "        res=sum((y-A.dot(x_phi))*(y-A.dot(x_phi)))\n",
    "        if res<res_min:\n",
    "            res_min=res\n",
    "            index_min=i\n",
    "\n",
    "\n",
    "    print('randwho and index_min',rand_who,index_min)\n",
    "#     print('detect and rand_who',detect,rand_who)\n",
    "#     print('rand_index',rand_index)\n",
    "#     print('rand_who',rand_who)\n",
    "#     print('*'*80)\n",
    "#     if detect == rand_who:\n",
    "#         right=right+1\n",
    "\n",
    "    if rand_who == index_min:\n",
    "        right=right+1\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svrg new version for time test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T20:52:52.526167Z",
     "start_time": "2018-10-26T20:52:42.953661Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('rand_index', 108)\n",
      "('randwho and index_min', 1, 45)\n"
     ]
    }
   ],
   "source": [
    "### import things\n",
    "import pandas as pd\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "### read form the csv doc\n",
    "data_train = pd.read_csv('train.csv')  \n",
    "data_test = pd.read_csv('test.csv')\n",
    "### trans to array\n",
    "train_array = np.array(data_train)\n",
    "test_array = np.array(data_test)\n",
    "###############hyper parameter\n",
    "use_normA=0\n",
    "use_normy=0\n",
    "###############hyper parameter\n",
    "\n",
    "###############functions\n",
    "\n",
    "### determin the x_tilda\n",
    "def cp(x):\n",
    "    return copy.deepcopy(x)\n",
    "\n",
    "### get w_tilda\n",
    "def compute_w_tilda(iters_inner,w_prev,ww_prev,all_or_one='mix',alpha=0.8,beta=0.2):\n",
    "    if all_or_one=='all':\n",
    "        w_tilda=cp(ww_prev)/iters_inner\n",
    "    elif all_or_one=='one':\n",
    "        w_tilda=cp(w_prev)\n",
    "    elif all_or_one=='mix':\n",
    "        w_tilda= cp(alpha*(w_prev)+beta*(ww_prev/iters_inner))\n",
    "    return w_tilda\n",
    "\n",
    "### get the data matrix A\n",
    "def get_A(use_normA,train_array):\n",
    "    if use_normA==1: \n",
    "        A_before_norm = train_array\n",
    "        A=np.empty(np.shape(A_before_norm))\n",
    "        for i in range(np.shape(A_before_norm)[1]):\n",
    "            temp=A_before_norm[:,i]/np.linalg.norm(A_before_norm[:,i])\n",
    "            A[:,i]=temp\n",
    "    else:\n",
    "        A = train_array\n",
    "    return A\n",
    "\n",
    "### get alpha \n",
    "def compute_alpha(A,lamb):\n",
    "    L_max=0.25*max(sum(A*A))\n",
    "    alpha=0.15/(L_max+lamb)\n",
    "    return alpha\n",
    "\n",
    "def get_xx_0():\n",
    "    xx_0=np.zeros([85*67,67])\n",
    "    for i in range(67):\n",
    "        xx_0[i*85:i*85+85][:,i]=1\n",
    "    return xx_0\n",
    "\n",
    "def compute_res(y,x_phi,lamb):\n",
    "    return sum((y-A.dot(x_phi))*(y-A.dot(x_phi)))\n",
    "    \n",
    "def get_index_min(xx_0,w_tilda):\n",
    "    res_min=1e9\n",
    "    for m in range(np.shape(xx_0)[1]):\n",
    "        temp=xx_0[:,m].reshape(5695,1)\n",
    "        x_phi=w_tilda*temp\n",
    "        res=compute_res(y,x_phi,lamb)\n",
    "        if res<res_min:\n",
    "            res_min=res\n",
    "            index_min=m\n",
    "    return index_min\n",
    "\n",
    "def compute_sci(xx_0,w):\n",
    "    w_l1=np.linalg.norm(w,ord=1)\n",
    "    temp_max=1e-9\n",
    "    for m in range(np.shape(xx_0)[1]):\n",
    "        temp=xx_0[:,m].reshape(5695,1)\n",
    "        x_phi=w_tilda*temp\n",
    "        x_phi_l1=np.linalg.norm(x_phi,ord=1)\n",
    "        if x_phi_l1>temp_max:\n",
    "            temp_max=x_phi_l1\n",
    "    return (67*(temp_max/w_l1)-1)/(67-1)\n",
    "\n",
    "\n",
    "\n",
    "###############functions\n",
    "\n",
    "\n",
    "### process the A to be norm or not\n",
    "A=get_A(0,train_array)\n",
    "[d,n] = A.shape\n",
    "\n",
    "\n",
    "### aha! same as the lambda, the L-1 norm coefficent\n",
    "lamb=1e-5\n",
    "\n",
    "### the learning rate 0.15/(the proxi-L constant)\n",
    "alpha=compute_alpha(A,lamb)\n",
    "\n",
    "### loops\n",
    "iters_outer=2\n",
    "iters_inner=2*d\n",
    "\n",
    "### count the number bingo\n",
    "right=0\n",
    "\n",
    "xx_0=get_xx_0()\n",
    "\n",
    "rand_index=108\n",
    "#     print('rand_index',rand_index)\n",
    "rand_who=int(rand_index/85)\n",
    "#     print('rand_who',rand_who)\n",
    "\n",
    "#### which y version you use, norm processed or the plain one \n",
    "if use_normy==1:\n",
    "    temp_y = test_array[:,rand_index].reshape(d,1)\n",
    "    y=np.empty(np.shape(temp_y))\n",
    "    y=temp_y/np.linalg.norm(temp_y)\n",
    "else:\n",
    "    y=test_array[:,rand_index].reshape(d,1)\n",
    "\n",
    "### initialize the two ws\n",
    "w_prev=np.array(np.zeros([n,1]))\n",
    "w_tilda=np.array(np.zeros([n,1]))\n",
    "\n",
    "### w_prev hotmap\n",
    "w_prev_hot=np.empty([n,1])\n",
    "hot_num=0\n",
    "\n",
    "### store the res and time\n",
    "res_list=[]\n",
    "time_list=[]\n",
    "sci_list=[]\n",
    "### count the time \n",
    "start = time.clock()\n",
    "for i in range(iters_outer):\n",
    "    mu=(-A.T).dot(y-A.dot(w_tilda))/d\n",
    "    ##small loop\n",
    "    for j in range(iters_inner):\n",
    "        ### choose a rand one from d \n",
    "        idx=np.random.randint(0,d)\n",
    "        ### A transpose, need reshape\n",
    "        A_idx=A[idx].T.reshape(n,1)\n",
    "        ### g_prev and tilda\n",
    "        g_prev=(-A_idx).dot(y[idx]-(A[idx].reshape(1,n)).dot(w_prev)) \n",
    "        g_tilda=(-A_idx).dot(y[idx]-(A[idx].reshape(1,n)).dot(w_tilda)) \n",
    "        ### update the parameter\n",
    "        w_prev=w_prev-alpha*(g_prev-g_tilda+mu)\n",
    "        ### the soft thresholding\n",
    "        temp=w_prev-lamb*alpha\n",
    "        temp=(temp+abs(temp))/2\n",
    "        w_prev=np.sign(w_prev)*temp\n",
    "        \n",
    "        ### compute the res of w_prev and store\n",
    "        res_now=sum((y-A.dot(w_prev))*(y-A.dot(w_prev)))\n",
    "        res_list.append(res_now)\n",
    "        time_list.append(time.clock()-start)\n",
    "        \n",
    "        ### compute the sci value of w_prev and store\n",
    "        sci_now=compute_sci(xx_0,w_prev)\n",
    "        sci_list.append(sci_now)\n",
    "        \n",
    "        ### make the w_prev_hot\n",
    "        w_prev_hot=np.concatenate((w_prev_hot,w_prev),axis=1)\n",
    "        \n",
    "    ### assign the w_tilda for another loop    \n",
    "    w_tilda=copy.deepcopy(w_prev)\n",
    "\n",
    "index_min=get_index_min(xx_0,w_tilda)\n",
    "\n",
    "        \n",
    "print(('rand_index',rand_index))\n",
    "print(('randwho and index_min',rand_who,index_min))\n",
    "\n",
    "if rand_who == index_min:\n",
    "    right=right+1\n",
    "    \n",
    "\n",
    "time_list_name=\"npy/sv1\"+'time_list'+'inner'+str(iters_inner)+'outer'+str(iters_outer)+'.npy'\n",
    "res_list_name=\"npy/sv1\"+'res_list'+'inner'+str(iters_inner)+'outer'+str(iters_outer)+'.npy'\n",
    "sci_list_name=\"npy/sv1\"+'sci_list'+'inner'+str(iters_inner)+'outer'+str(iters_outer)+'.npy'\n",
    "np.save(time_list_name,time_list)\n",
    "np.save(res_list_name,res_list)\n",
    "np.save(sci_list_name,sci_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T19:40:42.453160Z",
     "start_time": "2018-10-20T19:40:42.449172Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1 50\n",
    "2 83\n",
    "5 93\n",
    "10 98\n",
    "\n",
    "2 90 86 try for residial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TINY ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-21T07:39:25.862Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### import things\n",
    "import pandas as pd\n",
    "import copy\n",
    "### read form the csv doc\n",
    "data_train = pd.read_csv('train.csv')  \n",
    "\n",
    "data_test = pd.read_csv('test.csv')\n",
    "\n",
    "### trans to array\n",
    "train_array = np.array(data_train)\n",
    "test_array = np.array(data_test)\n",
    "###############hyper parameter\n",
    "use_normA=0\n",
    "use_normy=0\n",
    "###############hyper parameter\n",
    "\n",
    "### process the A to be norm or not\n",
    "if use_normA==1: \n",
    "    A_before_norm = train_array\n",
    "    A=np.empty(np.shape(A_before_norm))\n",
    "    for i in range(np.shape(A_before_norm)[1]):\n",
    "        temp=A_before_norm[:,i]/np.linalg.norm(A_before_norm[:,i])\n",
    "        A[:,i]=temp\n",
    "else:\n",
    "    A = train_array\n",
    "\n",
    "### the A shape\n",
    "[d,n] = A.shape\n",
    "\n",
    "\n",
    "### aha! same as the lambda, the L-1 norm coefficent\n",
    "lamb=1e-2\n",
    "\n",
    "### the learning rate 0.15/(the proxi-L constant)\n",
    "alpha=0.15/(0.25*max(sum(A*A)))\n",
    "\n",
    "### loops\n",
    "iters_outer=2\n",
    "iters_inner=2*d\n",
    "\n",
    "### count the number bingo\n",
    "right=0\n",
    "\n",
    "xx_0=np.zeros([85*67,67])\n",
    "for i in range(67):\n",
    "    xx_0[i*85:i*85+85][:,i]=1\n",
    "\n",
    "for k in range(100):\n",
    "    rand_index=np.random.randint(85*67)\n",
    "#     print('rand_index',rand_index)\n",
    "    rand_who=int(rand_index/85)\n",
    "#     print('rand_who',rand_who)\n",
    "    \n",
    "    #### which y version you use, norm processed or the plain one \n",
    "    if use_normy==1:\n",
    "        temp_y = test_array[:,rand_index].reshape(d,1)\n",
    "        y=np.empty(np.shape(temp_y))\n",
    "        y=temp_y/np.linalg.norm(temp_y)\n",
    "    else:\n",
    "        y=test_array[:,rand_index].reshape(d,1)\n",
    "    \n",
    "    ### initialize the two ws\n",
    "    w_prev=np.array(np.zeros([n,1]))\n",
    "    w_tilda=np.array(np.zeros([n,1]))\n",
    "    ### big loop\n",
    "    for i in range(iters_outer):\n",
    "        mu=(-A.T).dot(y-A.dot(w_tilda))/d\n",
    "        ##small loop\n",
    "        for j in range(iters_inner):\n",
    "            ### choose a rand one from d \n",
    "            idx=np.random.randint(0,d)\n",
    "            ### A transpose, need reshape\n",
    "            A_idx=A[idx].T.reshape(n,1)\n",
    "            ### g_prev and tilda\n",
    "            g_prev=(-A_idx).dot(y[idx]-(A[idx].reshape(1,n)).dot(w_prev)) \n",
    "            g_tilda=(-A_idx).dot(y[idx]-(A[idx].reshape(1,n)).dot(w_tilda)) \n",
    "            ### update the parameter\n",
    "            w_prev=w_prev-alpha*(g_prev-g_tilda+mu)\n",
    "            ### the soft thresholding\n",
    "            temp=w_prev-lamb*alpha\n",
    "            temp=(temp+abs(temp))/2\n",
    "            w_prev=np.sign(w_prev)*temp\n",
    "        ### assign the w_tilda for another loop    \n",
    "        w_tilda=copy.deepcopy(w_prev)\n",
    "\n",
    "\n",
    "        \n",
    "    res_min=1e9\n",
    "    for i in range(np.shape(xx_0)[1]):\n",
    "        temp=xx_0[:,i].reshape(5695,1)\n",
    "        x_phi=w_tilda*temp\n",
    "        res=sum((y-A.dot(x_phi))*(y-A.dot(x_phi)))\n",
    "        if res<res_min:\n",
    "            res_min=res\n",
    "            index_min=i\n",
    "\n",
    "\n",
    "    print('randwho and index_min',rand_who,index_min)\n",
    "#     print('detect and rand_who',detect,rand_who)\n",
    "#     print('rand_index',rand_index)\n",
    "#     print('rand_who',rand_who)\n",
    "#     print('*'*80)\n",
    "#     if detect == rand_who:\n",
    "#         right=right+1\n",
    "\n",
    "    if rand_who == index_min:\n",
    "        right=right+1\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-20T13:15:31.502Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "qq=pd.read_csv('traintiny.csv')\n",
    "qq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-20T13:15:36.390Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(qq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "30",
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "413px",
    "left": "1052.25px",
    "right": "20px",
    "top": "119.988px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
